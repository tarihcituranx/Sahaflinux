import streamlit as st
import requests
from PIL import Image
from io import BytesIO
import re

# --- SAYFA AYARLARI ---
st.set_page_config(
    page_title="Brave Destekli Sahaf",
    page_icon="ğŸ¦",
    layout="wide"
)

# --- API ANAHTARI KONTROLÃœ ---
try:
    API_KEY = st.secrets["BRAVE_API_KEY"]
except:
    st.error("âš ï¸ API AnahtarÄ± bulunamadÄ±! LÃ¼tfen .streamlit/secrets.toml dosyasÄ±nÄ± oluÅŸturun.")
    st.stop()

# --- METÄ°N TEMÄ°ZLEME FONKSÄ°YONU (GÃœNCELLENDÄ°) ---
def clean_ocr_text(text):
    """OCR metinlerindeki HTML etiketlerini ve bozukluklarÄ± temizler."""
    if not text:
        return ""
    
    # 1. HTML Etiketlerini Sil (<strong>, </b> vb.)
    text = re.sub(r'<[^>]+>', '', text)

    # 2. Gereksiz Sembolleri Sil (| iÅŸareti vb.)
    text = text.replace("|", "")

    # 3. Tire ile bÃ¶lÃ¼nmÃ¼ÅŸ kelimeleri birleÅŸtir (da- vasÄ± -> davasÄ±)
    text = re.sub(r'-\s+', '', text)

    # 4. Fazla boÅŸluklarÄ± temizle
    text = re.sub(r'\s+', ' ', text)

    # 5. YaygÄ±n OCR hatalarÄ±
    replacements = {
        " v e ": " ve ", " b ir ": " bir ", " b u ": " bu ", 
        " d e ": " de ", " d a ": " da ", " n e ": " ne ",
        " i Ã§ i n ": " iÃ§in ", " o l a n ": " olan ", " Ä± ": "Ä±", " i ": "i",
        " & ": " ", # & iÅŸareti genelde bozuk Ã§Ä±kÄ±yor
    }
    for old, new in replacements.items():
        text = text.replace(old, new)

    return text.strip()

# --- DOSYA Ä°SMÄ° VARYASYONLARI (AKILLI DENEME) ---
def generate_variations(date_str, page_num, suffix):
    """
    Sunucudaki olasÄ± dosya isimlerini Ã¼retir.
    Hem 1 hem 0 tabanlÄ± sayfa numaralarÄ±nÄ± dener.
    """
    variations = []
    try:
        y, m, d = date_str.split("-")
        p_num = int(page_num)
        
        # 1. Ä°htimal: Sayfa numarasÄ±nÄ±n 1 eksiÄŸi (0 tabanlÄ± indeksleme - Ã–rn: 1957-09-10-0.jpg)
        if p_num > 0:
            variations.append(f"{date_str}-{p_num - 1}{suffix}")
            variations.append(f"{date_str}-{p_num - 1:02d}{suffix}")

        # 2. Ä°htimal: Standart
        variations.append(f"{date_str}-{p_num}{suffix}")
        
        # 3. Ä°htimal: SÄ±fÄ±r dolgulu
        variations.append(f"{date_str}-{p_num:02d}{suffix}")
        
        # 4. Ä°htimal: SÄ±fÄ±rsÄ±z Tarih
        variations.append(f"{y}-{int(m)}-{int(d)}-{p_num}{suffix}")
        
        # 5. Ä°htimal: SÄ±fÄ±rsÄ±z Tarih + 1 EksiÄŸi
        if p_num > 0:
            variations.append(f"{y}-{int(m)}-{int(d)}-{p_num - 1}{suffix}")

    except:
        pass
    return variations

# --- GÃ–RÃœNTÃœ VE PDF Ä°ÅLEMLERÄ° ---

def get_cdn_image(gid, date_str, page_num):
    base_url = "https://dzp35pmd4yqn4.cloudfront.net/thumbnails"
    variations = generate_variations(date_str, page_num, "-thumbnail250.jpg")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Referer": "https://www.gastearsivi.com/"
    }

    for filename in variations:
        url = f"{base_url}/{gid}/{filename}"
        try:
            r = requests.get(url, headers=headers, timeout=2)
            if r.status_code == 200:
                return Image.open(BytesIO(r.content))
        except:
            continue
    return None

def download_pdf(gid, date_str, page_num):
    base_url = "https://dzp35pmd4yqn4.cloudfront.net/sayfalar"
    variations = generate_variations(date_str, page_num, ".jpg")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Referer": "https://www.gastearsivi.com/"
    }

    for filename in variations:
        url = f"{base_url}/{gid}/{filename}"
        try:
            # stream=True ile sadece varlÄ±ÄŸÄ±nÄ± kontrol et
            r = requests.get(url, headers=headers, timeout=5, stream=True)
            if r.status_code == 200:
                # Bulundu! Ä°ndir.
                img = Image.open(BytesIO(r.content)).convert("L")
                pdf_buffer = BytesIO()
                img.save(pdf_buffer, format="PDF", resolution=100.0, quality=85)
                pdf_buffer.seek(0)
                return pdf_buffer
        except:
            continue
    return None

# --- ARAMA FONKSÄ°YONU ---
def search_brave(keyword, count=20):
    url = "https://api.search.brave.com/res/v1/web/search"
    query = f'site:gastearsivi.com {keyword}'
    
    headers = {
        "Accept": "application/json",
        "Accept-Encoding": "gzip",
        "X-Subscription-Token": API_KEY
    }
    
    params = {"q": query, "count": count, "country": "tr", "safesearch": "off"}
    found_items = []
    
    try:
        response = requests.get(url, headers=headers, params=params)
        if response.status_code == 200:
            data = response.json()
            if "web" in data and "results" in data["web"]:
                results = data["web"]["results"]
                for r in results:
                    page_url = r["url"]
                    # AÃ§Ä±klama veya baÅŸlÄ±k alÄ±nÄ±yor
                    raw_desc = r.get("description", "") or r.get("title", "")
                    # HTML temizliÄŸi burada yapÄ±lÄ±yor
                    final_desc = clean_ocr_text(raw_desc)
                    
                    match = re.search(r"gazete\/([^\/]+)\/(\d{4}-\d{2}-\d{2})\/(\d+)", page_url)
                    if match:
                        gid = match.group(1)
                        date_str = match.group(2)
                        page_num = match.group(3)
                        g_name = gid.replace("_", " ").title()
                        
                        found_items.append({
                            "id": gid, "name": g_name, "date": date_str,
                            "page": page_num, "desc": final_desc, "url": page_url
                        })
        elif response.status_code == 429:
            st.warning("HÄ±z sÄ±nÄ±rÄ± aÅŸÄ±ldÄ±.")
        elif response.status_code == 401:
            st.error("API AnahtarÄ± geÃ§ersiz.")
    except Exception as e:
        st.error(f"Hata: {e}")
    return found_items

# --- SESSION STATE ---
if 'search_results' not in st.session_state:
    st.session_state.search_results = []
if 'pdf_cache' not in st.session_state:
    st.session_state.pdf_cache = {}

# --- ARAYÃœZ ---
st.title("ğŸ¦ Brave Destekli Dijital Sahaf")
st.markdown("Google'Ä±n engellerine takÄ±lmadan, **Brave API** gÃ¼cÃ¼yle arÅŸivde arama yapÄ±n.")

with st.sidebar:
    st.header("Arama AyarlarÄ±")
    keyword = st.text_input("Anahtar Kelime", placeholder="Ã–rn: 10 KasÄ±m, Hatay...")
    count_slider = st.slider("SonuÃ§ SayÄ±sÄ±", 10, 50, 20)
    
    if st.button("ARA ğŸ”", type="primary"):
        if keyword:
            with st.spinner("Brave arÅŸivi tarÄ±yor ve metinleri temizliyor..."):
                st.session_state.search_results = search_brave(keyword, count_slider)
                st.session_state.pdf_cache = {} 
        else:
            st.warning("LÃ¼tfen bir kelime girin.")
    
    st.info("Brave API, ayda 2000 aramaya kadar Ã¼cretsizdir.")

# SONUÃ‡LARI GÃ–STER
results = st.session_state.search_results

if results:
    st.success(f"âœ… {len(results)} sonuÃ§ bulundu.")
    st.markdown("---")
    
    for item in results:
        with st.container():
            c1, c2 = st.columns([1, 4])
            
            with c1:
                img = get_cdn_image(item['id'], item['date'], item['page'])
                if img:
                    st.image(img, use_container_width=True)
                else:
                    st.image("https://placehold.co/200x300?text=Resim+Yok", use_container_width=True)
                    
            with c2:
                st.subheader(f"{item['name']} - {item['date']}")
                st.caption(f"Sayfa: {item['page']}")
                st.write(f"_{item['desc']}_")
                
                col_dl, col_go = st.columns([1, 3])
                unique_id = f"{item['id']}_{item['date']}_{item['page']}"
                
                with col_dl:
                    if unique_id not in st.session_state.pdf_cache:
                        if st.button(f"ğŸ“¥ PDF HazÄ±rla", key=f"btn_{unique_id}"):
                            with st.spinner("ArÅŸiv taranÄ±yor (Varyasyonlar deneniyor)..."):
                                pdf_data = download_pdf(item['id'], item['date'], item['page'])
                                if pdf_data:
                                    st.session_state.pdf_cache[unique_id] = pdf_data
                                    st.rerun()
                                else:
                                    st.error("Dosya sunucuda bulunamadÄ±.")
                    else:
                        fname = f"{item['name']}_{item['date']}_S{item['page']}.pdf"
                        st.download_button(
                            label="ğŸ’¾ PDF Ä°NDÄ°R",
                            data=st.session_state.pdf_cache[unique_id],
                            file_name=fname,
                            mime="application/pdf",
                            key=f"dl_{unique_id}",
                            type="primary"
                        )

                with col_go:
                    st.markdown(f"[Orjinal Sayfaya Git]({item['url']})")
            st.divider()
